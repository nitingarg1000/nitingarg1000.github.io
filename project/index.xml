<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Nitin Garg</title>
    <link>https://nitingarg1000.github.io/project/</link>
      <atom:link href="https://nitingarg1000.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© Nitin Garg 2021</copyright><lastBuildDate>Wed, 21 Oct 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://nitingarg1000.github.io/img/pom-card.png</url>
      <title>Projects</title>
      <link>https://nitingarg1000.github.io/project/</link>
    </image>
    
    <item>
      <title>Conversational Agent for Mental Health</title>
      <link>https://nitingarg1000.github.io/project/mental-health/</link>
      <pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://nitingarg1000.github.io/project/mental-health/</guid>
      <description>&lt;p&gt;This project was mentored by 
&lt;a href=&#34;https://ashutosh-modi.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Ashutosh Modi&lt;/a&gt; where we attempted to improve a chat-bot that is in development by IIT Kanpur. We did the following -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Created a semi-automated self-help conversational agent that serves as a cost-effective mental health regulator.&lt;/li&gt;
&lt;li&gt;Designed a retrieval based system where the input is compared to existing conversations in the database using deep learning.&lt;/li&gt;
&lt;li&gt;Used neural network based architectures to find out the similarity between two pieces of texts to generate a response.&lt;/li&gt;
&lt;li&gt;Explored Natural Language Generation (NLG) techniques based on RNN and transformer based architectures.&lt;/li&gt;
&lt;li&gt;Pre-processed to convert the textual data into word embeddings to facilitate comparison among different texts.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Advanced Algorithms</title>
      <link>https://nitingarg1000.github.io/project/algorithms/</link>
      <pubDate>Mon, 27 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://nitingarg1000.github.io/project/algorithms/</guid>
      <description>&lt;p&gt;Algorithms are important in every area. I started with some basic algorithms like Sorting, Binary Search, Dynamic Programming, Disjoint Set Union, Hashing, String Prefix Structure, etc. I also got familiar with several other algorithms like DFS, BFS, Sieve of Eratosthenes, STL, Meet in the Middle Technique, etc. Further, I explored various Graph Algorithms like Dijkstra, Topological Sort, Floyd Warshall, Bellman Ford, Kruskal, Prim algorithm, etc. Apart from learning, I also implemented all of these in C++ to get a better understanding.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Breaking Cryptosystems</title>
      <link>https://nitingarg1000.github.io/project/crypto/</link>
      <pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://nitingarg1000.github.io/project/crypto/</guid>
      <description>&lt;p&gt;This project was a part of a course (CS641: Modern Cryptology) taught by 
&lt;a href=&#34;https://www.cse.iitk.ac.in/users/manindra/publications.html/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Manindra Agrawal&lt;/a&gt;. We performed Cyptanalysis of Substitution cipher, Block substitution cipher, Substitution-Permutation cipher. We also analyzed special cases of cryptanalysis of DES (Differential cryptanalysis), AES (SASAS attack), RSA with low exponent (Coppersmith attack). Towards the end, we learnt and worked through different attacks on weaker version on KECCAK hashing. We used python for implementing these cryptographic attacks and were able to break each of the above mentioned algorithms.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Variational Inference vs MCMC</title>
      <link>https://nitingarg1000.github.io/project/variational-inference-vs-mcmc/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://nitingarg1000.github.io/project/variational-inference-vs-mcmc/</guid>
      <description>&lt;p&gt;This project was my first introduction to statistics and was mentored by 
&lt;a href=&#34;https://dvats.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Dootika Vats&lt;/a&gt; where we covered the following milestones -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Got familiarised with Variational Inference &amp;amp; MCMC.&lt;/li&gt;
&lt;li&gt;Implemented an R program to obtain the posterior distribution for a dataset using both Variational Inference and MCMC.&lt;/li&gt;
&lt;li&gt;Obtained a contrast among posteriors obtained using both the techniques.&lt;/li&gt;
&lt;li&gt;Concluded that MCMC is asymptotically exact while VI is not but also computationally expensive.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Haskell Scrabble Solver</title>
      <link>https://nitingarg1000.github.io/project/haskell/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://nitingarg1000.github.io/project/haskell/</guid>
      <description>&lt;p&gt;I took this up as a self project to learnt the concepts of functional programming through Haskell, one of the most widely used functional programming languages. I then deep dived into the concepts of Type theory, Currying, Recursion, Immutability, File Systems, Pattern Matching and Laziness of Haskell. Using these concepts, I made a Scrabble Solver in Haskell (A Two Player version and a Play with Computer version) which used Lexicographical Search, Regex-type functions (written from scratch) and Quick Sort as the major algorithms.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Convex Optimization Techniques</title>
      <link>https://nitingarg1000.github.io/project/convex/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://nitingarg1000.github.io/project/convex/</guid>
      <description>&lt;p&gt;Convex optimization is a subfield of mathematical optimization that studies the problem of minimizing convex functions over convex sets. We started by studying the three parameter Weibull distribution and wrote a python script to maximize its likelihood function. We then got familiar with Batch Gradient Descent, Stochastic Gradient Descent and Mini-Batch Gradient Descent. We also explored several Matrix Factorization methods such as LU and PLU Factorization for basis B, Cholesky Factorization LLT and LDLT for Symmetric, Positive Definite Matrices B, etc. Further, we explored optimization techniques such as Adagrad, RMSProp, AdaMax, Adam, etc. We also implemented each of these techniques in python to visualize the differences.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Health Buddy (Web application)</title>
      <link>https://nitingarg1000.github.io/project/health-buddy/</link>
      <pubDate>Sat, 27 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://nitingarg1000.github.io/project/health-buddy/</guid>
      <description>&lt;p&gt;This project was part of my internship at IITK Summer of Code organised by the 
&lt;a href=&#34;https://www.cse.iitk.ac.in&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dept. of Computer Science and Engineering&lt;/a&gt;. The technical details are as follows -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Received intensive training in technologies involved in Full-Stack Development.&lt;/li&gt;
&lt;li&gt;Developed a web based platform which would make the entire process of the local health centre paper-free and improve the overall experience of a visit.&lt;/li&gt;
&lt;li&gt;Created separate end-points for various departments like reception, doctor, patient, pharmacy, etc.&lt;/li&gt;
&lt;li&gt;Efficient database handling for pharmacy to log in the inventory.&lt;/li&gt;
&lt;li&gt;Used Django framework in python as the backend framework and HTML, CSS, JS and Bootstrap for frontend development.&lt;/li&gt;
&lt;li&gt;PostgreSQL was used as the database manager.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Language Models</title>
      <link>https://nitingarg1000.github.io/project/language-models/</link>
      <pubDate>Sun, 14 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://nitingarg1000.github.io/project/language-models/</guid>
      <description>&lt;p&gt;I took up this project under 
&lt;a href=&#34;https://pclub.in&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Programming Club&lt;/a&gt;, IIT Kanpur. This was my first introduction to language models and the summary is as follows -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Got me familiarized with Deep Neural Networks by implementing the basic types of neural networks&lt;/li&gt;
&lt;li&gt;Learnt about the basics of Natural Language Processing and some common applications of sequence models with focus on word embeddings such as GloVe, Word2Vec, BERT, etc.&lt;/li&gt;
&lt;li&gt;Implemented a SOTA paper on ELMo’s (Embeddings for Language Models) in Python using Pytorch that achieved 83% efficiency which is close to 85.8% SOTA values&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
